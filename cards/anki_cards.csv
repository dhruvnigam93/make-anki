What is the mathematical definition of token entropy H_i in DeepConf?,"Token entropy at position i is defined as \[H_i = -\sum_j P_i(j) \log P_i(j)\] where \(P_i(j)\) represents the probability of the j-th vocabulary token. Low entropy indicates high model certainty (peaked distribution), while high entropy reflects uncertainty.",Paper,https://arxiv.org/pdf/2508.15260,Algorithms,This is a fundamental measure used in DeepConf to assess model confidence at the token level. Used as building block for more complex confidence measures.
How is token confidence C_i calculated in DeepConf?,Token confidence at position i is defined as \[C_i = -\frac{1}{k}\sum_{j=1}^k \log P_i(j)\] where k denotes the number of top tokens considered. High confidence corresponds to peaked distributions and greater model certainty.,Paper,https://arxiv.org/pdf/2508.15260,Algorithms,This is the negative average log-probability of the top-k tokens. Alternative to entropy-based measures for quantifying model uncertainty.
What is the formula for group confidence C_{G_i} in DeepConf?,"Group confidence for group G_i is defined as \[C_{G_i} = \frac{1}{|G_i|} \sum_{t \in G_i} C_t\] where |G_i| is the number of tokens in group G_i, and each group consists of n previous tokens (e.g., n=1024 or 2048) with overlapping adjacent windows.",Paper,https://arxiv.org/pdf/2508.15260,Algorithms,"Group confidence provides localized confidence signals by averaging token confidence over sliding windows, enabling detection of intermediate reasoning failures."
How does confidence-weighted majority voting work in DeepConf?,"Instead of treating each trace vote equally, the total vote weight for candidate answer a is \[V(a) = \sum_{t \in T} C_t \cdot I(\text{answer}(t) = a)\] where C_t is the trace-level confidence and I{·} is the indicator function. The final answer is selected as \(\hat{a} = \arg\max_a V(a)\).",Paper,https://arxiv.org/pdf/2508.15260,Algorithms,"This voting scheme favors answers supported by high-confidence traces, reducing the impact of uncertain or low-quality reasoning paths compared to standard majority voting."
How does DeepConf implement confidence filtering in the offline setting?,"Confidence filtering selects the top-η percent of traces based on trace confidence scores. Two options: η=10% focuses on highest confidence scores (suitable when few reliable traces expected), η=90% offers balanced approach maintaining diversity while reducing model bias.",Paper,https://arxiv.org/pdf/2508.15260,Algorithms,"The filtering percentage η represents a key trade-off: aggressive filtering (10%) maximizes accuracy gains but risks model overconfidence, while conservative filtering (90%) provides safer performance."
